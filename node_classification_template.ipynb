{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "\"\"\"GCN using DGL nn package\n",
    "\n",
    "References:\n",
    "- Semi-Supervised Classification with Graph Convolutional Networks\n",
    "- Paper: https://arxiv.org/abs/1609.02907\n",
    "- Code: https://github.com/tkipf/gcn\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from dgl.nn.pytorch import GraphConv\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 g,\n",
    "                 in_feats,\n",
    "                 n_hidden,\n",
    "                 n_classes,\n",
    "                 activation,\n",
    "                 dropout=0.5):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.g = g\n",
    "\n",
    "        self.gcn_layer1 = GraphConv(in_feats, n_hidden, activation=activation)\n",
    "\n",
    "        self.gcn_layer2 = GraphConv(n_hidden, n_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, features):\n",
    "        h = features\n",
    "\n",
    "        h = self.gcn_layer1(self.g, h)\n",
    "\n",
    "        h = self.dropout(h)\n",
    "\n",
    "        h = self.gcn_layer2(self.g, h)\n",
    "\n",
    "        return h\n",
    "\n",
    "    def freeze_features(self, freeze):\n",
    "        self.emb.weight.requires_grad = not freeze\n",
    "\n",
    "    def freeze_graph(self, freeze):\n",
    "        self.gcn_layer1.weight.requires_grad = not freeze\n",
    "        self.gcn_layer2.weight.requires_grad = not freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masks(n,\n",
    "              main_ids,\n",
    "              main_labels,\n",
    "              test_ratio,\n",
    "              val_ratio,\n",
    "              seed=1):\n",
    "    \"\"\"\n",
    "    Randomly splits data into train/val/test using random seed\n",
    "    returns masks instead of the data itself  \n",
    "    \"\"\"\n",
    "    train_mask = np.zeros(n)\n",
    "    val_mask = np.zeros(n)\n",
    "    test_mask = np.zeros(n)\n",
    "\n",
    "    x_dev, x_test, y_dev, y_test = train_test_split(main_ids,\n",
    "                                                    main_labels,\n",
    "                                                    stratify=main_labels,\n",
    "                                                    test_size=test_ratio,\n",
    "                                                    random_state=seed)\n",
    "\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_dev,\n",
    "                                                      y_dev,\n",
    "                                                      stratify=y_dev,\n",
    "                                                      test_size=val_ratio,\n",
    "                                                      random_state=seed)\n",
    "\n",
    "    train_mask[x_train] = 1\n",
    "    val_mask[x_val] = 1\n",
    "    test_mask[x_test] = 1\n",
    "\n",
    "    return train_mask, val_mask, test_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, features, labels, mask):\n",
    "    \"\"\"\n",
    "    Evaluate model quality (F1-score)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask].detach().cpu().numpy()\n",
    "        _, predicted = torch.max(logits, dim=1)\n",
    "        predicted = predicted.detach().cpu().numpy()\n",
    "        f1 = f1_score(labels, predicted, average='micro')\n",
    "        return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REPLACE HERE WITH YOUR MODEL\n",
    "\n",
    "MODEL = GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dgl\n",
    "from dgl import DGLGraph\n",
    "\n",
    "def train_gcn(dataset,\n",
    "              test_ratio=0.5,\n",
    "              val_ratio=0.2,\n",
    "              seed=1,\n",
    "              n_hidden=64,\n",
    "              n_epochs=200,\n",
    "              lr=1e-2,\n",
    "              weight_decay=5e-4,\n",
    "              dropout=0.5,\n",
    "              verbose=True,\n",
    "              cuda=False):\n",
    "    data = dataset.get_data()\n",
    "\n",
    "    features = torch.FloatTensor(data['features'])\n",
    "    labels = torch.LongTensor(data['labels'])\n",
    "\n",
    "    n = len(data['ids'])\n",
    "    train_mask, val_mask, test_mask = get_masks(n,\n",
    "                                                data['main_ids'],\n",
    "                                                data['main_labels'],\n",
    "                                                test_ratio=test_ratio,\n",
    "                                                val_ratio=val_ratio,\n",
    "                                                seed=seed)\n",
    "\n",
    "    train_mask = torch.BoolTensor(train_mask)\n",
    "    val_mask = torch.BoolTensor(val_mask)\n",
    "    test_mask = torch.BoolTensor(test_mask)\n",
    "\n",
    "    if cuda:\n",
    "        torch.cuda.set_device(\"cuda:0\")\n",
    "        features = features.cuda()\n",
    "        labels = labels.cuda()\n",
    "        train_mask = train_mask.cuda()\n",
    "        val_mask = val_mask.cuda()\n",
    "        test_mask = test_mask.cuda()\n",
    "\n",
    "    g = DGLGraph(data['graph'])\n",
    "    g = dgl.transform.add_self_loop(g)\n",
    "    n_edges = g.number_of_edges()\n",
    "\n",
    "    degs = g.in_degrees().float()\n",
    "    norm = torch.pow(degs, -0.5)\n",
    "    norm[torch.isinf(norm)] = 0\n",
    "\n",
    "    if cuda:\n",
    "        norm = norm.cuda()\n",
    "\n",
    "    g.ndata['norm'] = norm.unsqueeze(1)\n",
    "\n",
    "    in_feats = features.shape[1]\n",
    "\n",
    "    # + 1 for unknown class\n",
    "    n_classes = data['n_classes'] + 1\n",
    "    \n",
    "    ##########\n",
    "    ##########  HERE WE USE MODEL\n",
    "    ##########\n",
    "    model = MODEL(g,\n",
    "                in_feats=in_feats,\n",
    "                n_hidden=n_hidden,\n",
    "                n_classes=n_classes,\n",
    "                activation=F.relu,\n",
    "                dropout=dropout)\n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fcn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # use optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                 lr=lr,\n",
    "                                 weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                           mode='min',\n",
    "                                                           factor=0.9,\n",
    "                                                           patience=20,\n",
    "                                                           min_lr=1e-10)\n",
    "\n",
    "    best_f1 = -100\n",
    "    # initialize graph\n",
    "    dur = []\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        if epoch >= 3:\n",
    "            t0 = time.time()\n",
    "        # forward\n",
    "        logits = model(features)\n",
    "        loss = loss_fcn(logits[train_mask], labels[train_mask])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch >= 3:\n",
    "            dur.append(time.time() - t0)\n",
    "\n",
    "        f1 = evaluate(model, features, labels, val_mask)\n",
    "        scheduler.step(1 - f1)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | F1 {:.4f} | \"\n",
    "                  \"ETputs(KTEPS) {:.2f}\".format(epoch, np.mean(dur), loss.item(),\n",
    "                                                f1, n_edges / np.mean(dur) / 1000))\n",
    "\n",
    "    model.load_state_dict(torch.load('best_model.pt'))\n",
    "    f1 = evaluate(model, features, labels, test_mask)\n",
    "\n",
    "    if verbose:\n",
    "        print()\n",
    "        print(\"Test F1 {:.2}\".format(f1))\n",
    "\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Cora, CiteseerM10, Dblp\n",
    "\n",
    "datasets = [\n",
    "   ('Cora', Cora),\n",
    "   # ('CiteseerM10', CiteseerM10),\n",
    "   # ('DBLP', Dblp)\n",
    "]\n",
    "\n",
    "\n",
    "from text_transformers import SBert, LDA, W2V, Sent2Vec, Doc2Vec, BOW, TFIDF\n",
    "\n",
    "text_transformers = [\n",
    "    (\"W2V(d=64)\", W2V(train=True, d=64))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [1]\n",
    "test_ratios = [0.5, 0.7, 0.9, 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "datasets:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "transformers:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "test ratio:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "test ratio:  25%|██▌       | 1/4 [00:02<00:06,  2.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "test ratio:  50%|█████     | 2/4 [00:04<00:04,  2.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "test ratio:  75%|███████▌  | 3/4 [00:06<00:02,  2.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "test ratio: 100%|██████████| 4/4 [00:07<00:00,  1.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "transformers: 100%|██████████| 1/1 [00:27<00:00, 27.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "datasets: 100%|██████████| 1/1 [00:27<00:00, 27.82s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "res = {}\n",
    "for ds_name, ds_constr in tqdm(datasets, desc='datasets'):\n",
    "    ds = ds_constr()\n",
    "    for text_trans_name, text_transofmer in tqdm(text_transformers, \"transformers\"):\n",
    "        ds.transform_features(text_transofmer)\n",
    "        for test_ratio in tqdm(test_ratios, desc='test ratio'):\n",
    "            scores = []\n",
    "            for seed in seeds:\n",
    "                score = train_gcn(ds, test_ratio, seed=seed, verbose=False)\n",
    "                scores.append(score)\n",
    "\n",
    "            res[f'{1 - test_ratio:.2f} - {ds_name} - GCN {text_trans_name}'] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.50 - Cora - GCN W2V(d=64) [0.8412112259970459] 0.8412112259970459 0.0\n",
      "0.30 - Cora - GCN W2V(d=64) [0.814873417721519] 0.814873417721519 0.0\n",
      "0.10 - Cora - GCN W2V(d=64) [0.8096800656275636] 0.8096800656275636 0.0\n",
      "0.05 - Cora - GCN W2V(d=64) [0.7835211815001943] 0.7835211815001943 0.0\n"
     ]
    }
   ],
   "source": [
    "for name, scores in res.items():\n",
    "    print(name, scores, np.mean(scores), np.std(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:graph_text]",
   "language": "python",
   "name": "conda-env-graph_text-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
